    7  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '3e-5' --seq_length 512 --use_peft --output_dir output --load_in_4bit true --batch_size=2
   12  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '3e-5' --seq_length 512 --use_peft --output_dir output --load_in_4bit true --batch_size=2
   13  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '3e-5' --seq_length 512 --use_peft --output_dir output --load_in_4bit true --batch_size=4
   20  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '3e-5' --seq_length 1024 --use_peft --output_dir output --load_in_4bit true --batch_size=2
   21  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '3e-5' --seq_length 1024 --use_peft --output_dir output --load_in_4bit true --batch_size=1 --help
   22  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '3e-5' --seq_length 1024 --use_peft --output_dir output --load_in_4bit true --batch_size=1 --gradient_checkpointing true
   23  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '3e-5' --seq_length 1024 --use_peft --output_dir output --load_in_4bit true --batch_size=8 --gradient_checkpointing true
   25  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '3e-5' --seq_length 1024 --use_peft --output_dir output --load_in_4bit true --batch_size=16 --gradient_accumulation_steps=4 --gradient_checkpointing true
   26  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '3e-5' --seq_length 2048 --use_peft --output_dir output --load_in_4bit true --batch_size=16 --gradient_accumulation_steps=4 --gradient_checkpointing true
   27  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '2e-5' --seq_length 2048 --use_peft --output_dir output --load_in_4bit true --batch_size=16 --gradient_accumulation_steps=4 --gradient_checkpointing true --peft_lora_r 32
   28  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '2e-5' --seq_length 2048 --use_peft --output_dir output --batch_size=8 --gradient_accumulation_steps=8 --gradient_checkpointing true --peft_lora_r 32
   29  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '2e-5' --seq_length 2048 --use_peft --output_dir output --batch_size=4 --gradient_accumulation_steps=16 --gradient_checkpointing true --peft_lora_r 32
   30  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '2e-5' --seq_length 1024 --use_peft --output_dir output --batch_size=4 --gradient_accumulation_steps=16 --gradient_checkpointing true --peft_lora_r 64
   31  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '2e-5' --seq_length 1024 --use_peft --output_dir output --batch_size=8 --gradient_accumulation_steps=8 --gradient_checkpointing true --peft_lora_r 64
   32  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '2e-5' --seq_length 1024 --use_peft --output_dir output --batch_size=16 --gradient_accumulation_steps=4 --gradient_checkpointing true --peft_lora_r 64
   33  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '1.42e-5' --seq_length 1024 --use_peft --output_dir output --batch_size=16 --gradient_accumulation_steps=4 --gradient_checkpointing true --peft_lora_r 64
   38  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '1.42e-5' --seq_length 1024 --use_peft --output_dir output --batch_size=16 --gradient_accumulation_steps=4 --gradient_checkpointing true --peft_lora_r 64 --num_train_epochs=12
   57  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '1.42e-5' --seq_length 512 --use_peft --output_dir output --batch_size=16 --gradient_accumulation_steps=4 --gradient_checkpointing true --peft_lora_r 64 --num_train_epochs=12
   58  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '1.42e-5' --seq_length 512 --use_peft --output_dir output --batch_size=16 --gradient_accumulation_steps=4 --gradient_checkpointing true --peft_lora_r 64 --num_train_epochs=3
   59  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '1.42e-5' --seq_length 512 --use_peft --output_dir output --batch_size=16 --gradient_checkpointing true --peft_lora_r 64 --num_train_epochs=3
   60  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '1.42e-5' --seq_length 512 --use_peft --output_dir output --batch_size=32 --gradient_checkpointing false  --peft_lora_r 128 --num_train_epochs=3
   61  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '1.42e-5' --seq_length 512 --use_peft --output_dir output --batch_size=16 --gradient_checkpointing false  --peft_lora_r 128 --num_train_epochs=3
   62  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '1.42e-5' --seq_length 32 --use_peft --output_dir output --batch_size=16 --gradient_checkpointing false  --peft_lora_r 64 --num_train_epochs=3
   63  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '1.42e-5' --seq_length 32 --use_peft --output_dir output --batch_size=16 --gradient_checkpointing false  --peft_lora_r 64 --num_train_epochs=3 --target_modules=all
   64  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '1.42e-5' --seq_length 32 --use_peft --output_dir output --batch_size=16 --gradient_checkpointing false  --peft_lora_r 64 --num_train_epochs=3
   65  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '1.42e-5' --seq_length 32 --use_peft --output_dir output --batch_size=16 --gradient_checkpointing false  --peft_lora_r 64 --num_train_epochs=10
   66  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '1.42e-5' --seq_length 256 --use_peft --output_dir output --batch_size=16 --gradient_checkpointing false  --peft_lora_r 64 --num_train_epochs=10
   67  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '1.42e-5' --seq_length 256 --use_peft --output_dir output --batch_size=8 --gradient_checkpointing false  --peft_lora_r 64 --num_train_epochs=10
   68  #python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '1.42e-5' --seq_length 256 --use_peft --output_dir output --batch_size=8 --gradient_checkpointing false  --peft_lora_r 64 --num_train_epochs=10
   77  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '1.42e-5' --seq_length 256 --use_peft --output_dir output --batch_size=8 --gradient_checkpointing false  --peft_lora_r 64 --num_train_epochs=100
   78  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '2e-4' --seq_length 512 --use_peft --output_dir output --batch_size=16 --gradient_checkpointing false  --peft_lora_r 64 --num_train_epochs=100
   79  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '2e-4' --seq_length 512 --use_peft --output_dir output --batch_size=8 --gradient_accumulation_steps=2 --gradient_checkpointing false  --peft_lora_r 64 --num_train_epochs=100
   80  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '2e-4' --seq_length 512 --use_peft --output_dir output --batch_size=16 --load_in_4bit=true --gradient_checkpointing false  --peft_lora_r 64 --num_train_epochs=100
   81  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '2e-4' --seq_length 512 --use_peft --output_dir output --batch_size=8 --gradient_accumulation_steps=2 --gradient_checkpointing false  --peft_lora_r 64 --num_train_epochs=100
   82  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '2e-4' --seq_length 512 --use_peft --output_dir output --batch_size=4 --gradient_accumulation_steps=4 --gradient_checkpointing false  --peft_lora_r 64 --num_train_epochs=100
   83  #python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '2e-4' --seq_length 512 --use_peft --output_dir output --batch_size=4 --gradient_accumulation_steps=4 --gradient_checkpointing false  --peft_lora_r 64 --num_train_epochs=100
   86  python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '2e-4' --seq_length 512 --use_peft --output_dir output --batch_size=16 --gradient_checkpointing true  --peft_lora_r 64 --num_train_epochs=100
  101  #python examples/scripts/sft.py --model_name "mistralai/Mistral-7B-v0.1" --dataset_name "timdettmers/openassistant-guanaco" --dataset_text_field text --report_to wandb --learning_rate '2e-4' --seq_length 512 --use_peft --output_dir output --batch_size=16 --gradient_checkpointing true  --peft_lora_r 64 --num_train_epochs=100
  119  python ./examples/scripts/dpo.py   --model_name_or_path="microsoft/phi-2"   --trust_remote_code
  121  python ./examples/scripts/dpo.py   --model_name_or_path="microsoft/phi-2"   --trust_remote_code
  122  python ./examples/scripts/dpo.py   
  123  python ./examples/scripts/dpo.py   --model_name_or_path="microsoft/phi-2"   --trust_remote_code
  125  python ./examples/scripts/dpo.py   --model_name_or_path="mistralai/Mistral-7B-v0.1"   --trust_remote_code
  126  python ./examples/scripts/dpo.py   --model_name_or_path="mistralai/Mistral-7B-v0.1"   --trust_remote_code --learning_rate=2e-4
  127  python ./examples/scripts/dpo.py   --model_name_or_path="microsoft/phi-2"   --trust_remote_code --learning_rate=2e-4
  128  #python ./examples/scripts/dpo.py   --model_name_or_path="microsoft/phi-2"   --trust_remote_code --learning_rate=2e-4
  130  python ./examples/scripts/sft.py --model_name="microsoft/phi-2" --trust_remote_code --learning_rate=2e-4
  131  python ./examples/scripts/sft.py --model_name="microsoft/phi-2" --trust_remote_code --learning_rate=2e-4 --use_peft
  132  python ./examples/scripts/sft.py --model_name="microsoft/phi-2" --trust_remote_code --learning_rate=2e-4 --use_peft --report_to=wandb
  133  python ./examples/scripts/sft.py --model_name="microsoft/phi-2" --trust_remote_code --learning_rate=3e-4 --use_peft --report_to=wandb
  134  python ./examples/scripts/sft.py --model_name="microsoft/phi-2" --trust_remote_code --learning_rate=2e-4 --use_peft --report_to=wandb
  135  python ./examples/scripts/sft.py --model_name="microsoft/phi-2" --trust_remote_code --learning_rate=2e-4 --use_peft --report_to=wandb --load_in_4bit
  136  python ./examples/scripts/sft.py --model_name="microsoft/phi-2" --trust_remote_code --learning_rate=2e-4 --use_peft --report_to=wandb 
  138  python ./examples/scripts/sft.py --model_name="microsoft/phi-2" --trust_remote_code --learning_rate=2e-4 --use_peft --report_to=wandb 
  139  python ./examples/scripts/sft.py --model_name="microsoft/phi-2" --trust_remote_code --learning_rate=2e-4 --use_peft --report_to=wandb --gradient_checkpointing=True
  140  python ./examples/scripts/sft.py --model_name="microsoft/phi-2" --trust_remote_code --learning_rate=2e-4 --use_peft --report_to=wandb
  142  history | grep python > lambda_a100_history
